# AI Band Ecosystem - Project Structure Templates

## ğŸ¸ ai-band-plugin (C++ JUCE)

```
ai-band-plugin/
â”œâ”€â”€ Source/
â”‚   â”œâ”€â”€ PluginProcessor.cpp      # Main audio processor
â”‚   â”œâ”€â”€ PluginProcessor.h        # Audio processor header
â”‚   â”œâ”€â”€ PluginEditor.cpp         # GUI implementation
â”‚   â”œâ”€â”€ PluginEditor.h           # GUI header
â”‚   â”œâ”€â”€ MidiManager.cpp          # MIDI file handling
â”‚   â”œâ”€â”€ MidiManager.h            # MIDI manager header
â”‚   â”œâ”€â”€ OrchestratorClient.cpp   # HTTP communication
â”‚   â”œâ”€â”€ OrchestratorClient.h     # HTTP client header
â”‚   â”œâ”€â”€ ChordAnalyzer.cpp        # Real-time chord detection
â”‚   â””â”€â”€ ChordAnalyzer.h          # Chord analyzer header
â”œâ”€â”€ JuceLibraryCode/             # JUCE framework files
â”œâ”€â”€ Builds/                      # Platform-specific builds
â”‚   â”œâ”€â”€ VisualStudio2022/        # Windows (VS)
â”‚   â”œâ”€â”€ Xcode/                   # macOS
â”‚   â””â”€â”€ LinuxMakefile/           # Linux
â”œâ”€â”€ Resources/                   # UI assets, presets
â”œâ”€â”€ Tests/                       # Unit tests
â”œâ”€â”€ README.md                    # Plugin documentation
â”œâ”€â”€ CMakeLists.txt              # CMake build config
â””â”€â”€ ai-band-plugin.jucer        # JUCE project file
```

### Key Plugin Classes
```cpp
class AIBandProcessor : public AudioProcessor {
    // Audio processing and MIDI handling
    void processBlock(AudioBuffer<float>&, MidiBuffer&);
    void handleMIDI(const MidiBuffer&);
};

class MidiManager {
    // MIDI file import/export
    bool loadMIDIFile(const String& path);
    void saveMIDIFile(const MidiFile&, const String& path);
};

class OrchestratorClient {
    // Communication with orchestrator
    Result generateTracks(const ChordProgression&);
    Result getGeneratedFiles();
};
```

## ğŸ›ï¸ ai-band-orchestrator (Python FastAPI)

```
ai-band-orchestrator/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”œâ”€â”€ config.py                # Configuration settings
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requests.py          # Pydantic request models
â”‚   â”‚   â””â”€â”€ responses.py         # Pydantic response models
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ generation.py    # Track generation endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py      # Chord analysis endpoints
â”‚   â”‚   â”‚   â””â”€â”€ files.py         # File serving endpoints
â”‚   â”‚   â””â”€â”€ websocket.py         # WebSocket handlers
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ backend_client.py    # AI Band Backend integration
â”‚   â”‚   â”œâ”€â”€ file_manager.py      # MIDI file management
â”‚   â”‚   â””â”€â”€ cache_manager.py     # Caching system
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py           # Logging configuration
â”‚       â””â”€â”€ validators.py        # Input validation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_generation.py       # Generation endpoint tests
â”‚   â”œâ”€â”€ test_websocket.py        # WebSocket tests
â”‚   â””â”€â”€ test_integration.py      # Backend integration tests
â”œâ”€â”€ generated/                   # Generated MIDI files directory
â”œâ”€â”€ logs/                        # Application logs
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ docker-compose.yml           # Docker deployment
â”œâ”€â”€ Dockerfile                   # Docker image
â”œâ”€â”€ README.md                    # Server documentation
â””â”€â”€ run.py                       # Application entry point
```

### Key Server Modules
```python
# app/services/backend_client.py
class BackendClient:
    def generate_tracks(self, chords, tempo, key):
        # Use ai-band-backend
        
# app/api/endpoints/generation.py
@router.post("/generate")
async def generate_tracks(request: GenerationRequest):
    # Handle track generation

# app/api/websocket.py
@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    # Real-time communication
```

## ğŸ”— Integration Dependencies

### ai-band-plugin Dependencies
```cmake
# CMakeLists.txt additions
find_package(CURL REQUIRED)      # HTTP client
find_package(nlohmann_json REQUIRED)  # JSON parsing

target_link_libraries(ai-band-plugin 
    PRIVATE
    juce::juce_audio_plugin_client
    juce::juce_audio_utils
    CURL::libcurl
    nlohmann_json::nlohmann_json
)
```

### ai-band-orchestrator Dependencies
```python
# Backend integration setup
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'ai-band-backend', 'src'))

from chord_detection import ChordDetector
from midi_generator import MidiGenerator
```

## ğŸš€ Development Workflow

### 1. Setup Order
```bash
# 1. Verify backend is working
cd ai-band-backend
python run_all_tests.py

# 2. Create orchestrator
cd ../ai-band-orchestrator  
python -m venv venv
pip install -r requirements.txt
python run.py

# 3. Create plugin
cd ../ai-band-plugin
# Setup JUCE project
# Build and test
```

### 2. Testing Integration
```bash
# Terminal 1: Start orchestrator
cd ai-band-orchestrator
python run.py

# Terminal 2: Test REST API
curl -X POST http://localhost:8080/generate \
  -H "Content-Type: application/json" \
  -d '{"chords": [{"chord": "C", "start_time": 0, "duration": 2}], "tempo": 120}'

# Terminal 3: Test with plugin
# Load plugin in DAW
# Send chord progression
# Verify MIDI playback
```

### 3. File Sharing Strategy
```
shared_output/
â”œâ”€â”€ midi_files/
â”‚   â”œâ”€â”€ bass_<timestamp>.mid
â”‚   â”œâ”€â”€ drum_<timestamp>.mid
â”‚   â””â”€â”€ combined_<timestamp>.mid
â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ generation_<timestamp>.json
â””â”€â”€ cache/
    â””â”€â”€ chord_analysis_cache.json
```

## ğŸ“Š Communication Flow

```
Guitar Input â†’ Plugin â†’ Orchestrator â†’ Backend â†’ Generation
     â†“             â†“         â†“           â†“         â†“
  MIDI Data â†’ Chord Data â†’ REST API â†’ Analysis â†’ MIDI Files
     â†“             â†“         â†“           â†“         â†“
  DAW Audio â†  Plugin  â†  WebSocket â†  Server  â†  Files
```

## ğŸ¯ Success Criteria

### Plugin (C++ JUCE)
- [ ] Loads as VST/AU in major DAWs
- [ ] Captures real-time MIDI input
- [ ] Communicates with orchestrator via HTTP
- [ ] Plays generated MIDI tracks
- [ ] Provides intuitive user interface

### Orchestrator (Python)
- [ ] Integrates seamlessly with ai-band-backend
- [ ] Provides REST API for track generation
- [ ] Handles WebSocket connections
- [ ] Manages file serving and cleanup
- [ ] Includes proper error handling and logging

### Integration
- [ ] End-to-end latency < 500ms
- [ ] Handles concurrent requests
- [ ] Graceful error recovery
- [ ] Compatible with major DAWs
- [ ] Professional audio quality

---

**Use this structure as a foundation for creating the companion projects. The ai-band-backend provides the core AI functionality, while these projects handle user interaction and real-time processing.**
